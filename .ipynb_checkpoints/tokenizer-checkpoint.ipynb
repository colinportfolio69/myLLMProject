{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0280541d-b324-451a-84dc-3962ec570cd4",
   "metadata": {},
   "source": [
    "# TRAINING BIGRAM MODEL - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691ef84-2cb8-4d8b-ab5b-b5ef6252f3d7",
   "metadata": {},
   "source": [
    "## Code for the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2aec26-fcc2-408e-b839-a6779e15b4b4",
   "metadata": {},
   "source": [
    "Language models work most best when text inputs are broken down into basic units, called tokens. \n",
    "\n",
    "For this simple bigram, the tokens can be the individual letters of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af219619-5dcd-4b71-9bb4-15d7f49afd2f",
   "metadata": {},
   "source": [
    "The tokenizer function below will first take each character and convert it into an integer as a numerical representation, which forms the token to train the bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15181778-b67f-4a3d-b5d1-dab98e03b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer():\n",
    "\n",
    "    # Store the content of\"Wizard of Oz\" into the variable, book.\n",
    "    with open(\"./wizardOfOz/pg22566_edited.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        book = f.read()\n",
    "        f.close()\n",
    "\n",
    "    # Collect the unique characters that appear in the book.\n",
    "    chars = sorted(set(book))\n",
    "\n",
    "    # Assign a integer value to each character.\n",
    "    tokens = []\n",
    "    meaning = -1\n",
    "    for i in chars:\n",
    "        meaning += 1\n",
    "        tokens.append(meaning)\n",
    "    \n",
    "    # Link character with integer meaning.\n",
    "    mapping = dict(zip(chars, tokens))\n",
    "\n",
    "    # take input from user\n",
    "    text = input(\"What is the phrase to convert? \")\n",
    "    tokenized = []\n",
    "    for i in text:\n",
    "        tokenized.append(mapping[i])\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586d9566-922a-4e5d-a8a1-b1d30b98f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the phrase to convert?  TOKENS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[44, 39, 35, 29, 38, 43]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a2b76-9fee-4e79-a102-92ecbf8797ea",
   "metadata": {},
   "source": [
    "## Code breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fabf64a-27bc-4391-8a46-1f7803ca2f31",
   "metadata": {},
   "source": [
    "Open the book, \"Dorothy and the Wizard of Oz\" and store the contents inside a string variable, named book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ef549d-94a6-417d-ba3f-8e3e617f35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./wizardOfOz/pg22566_edited.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    # Store the book in a string variable, book.\n",
    "    book = f.read()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54bacee-9ca8-4949-852d-df35d99f486f",
   "metadata": {},
   "source": [
    "Convert book from a string into a set element, in order to remove duplicate values such that each unique letter in the book is collected.\n",
    "\n",
    "Since set() doesn't list results alphabetically, use sorted() to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84a1b6e-9038-4722-9805-ba6f8b364f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the characters that appeared at least once in Wizard of Oz.\n",
      "\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(book))\n",
    "\n",
    "print(\"These are the characters that appeared at least once in Wizard of Oz.\\n\")\n",
    "\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf8a54-da03-4b41-981f-ca029bd29791",
   "metadata": {},
   "source": [
    "Assign each of these chracters with an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e13cf3-4d43-4174-a701-959e8eab6a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "meaning = -1\n",
    "for i in chars:\n",
    "    meaning += 1\n",
    "    tokens.append(meaning)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142570ff-e08a-4c91-bb66-905b995badac",
   "metadata": {},
   "source": [
    "The dictionary data type using key-value pairs is the most suitable for mapping characters to their integer tokens.\n",
    "\n",
    "To convert characters and token lists into a dictionary, use zip function to pair the values together, then use dict() function on the resulting zip object. (Read Basic Reminders section.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d39f2f-e9b4-4dad-ace6-5eb9c6d0d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('\\n', 0), (' ', 1), ('!', 2), ('\"', 3), ('&', 4), (\"'\", 5), ('(', 6), (')', 7), ('*', 8), (',', 9), ('-', 10), ('.', 11), ('0', 12), ('1', 13), ('2', 14), ('3', 15), ('4', 16), ('5', 17), ('6', 18), ('7', 19), ('8', 20), ('9', 21), (':', 22), (';', 23), ('?', 24), ('A', 25), ('B', 26), ('C', 27), ('D', 28), ('E', 29), ('F', 30), ('G', 31), ('H', 32), ('I', 33), ('J', 34), ('K', 35), ('L', 36), ('M', 37), ('N', 38), ('O', 39), ('P', 40), ('Q', 41), ('R', 42), ('S', 43), ('T', 44), ('U', 45), ('V', 46), ('W', 47), ('X', 48), ('Y', 49), ('Z', 50), ('[', 51), (']', 52), ('_', 53), ('a', 54), ('b', 55), ('c', 56), ('d', 57), ('e', 58), ('f', 59), ('g', 60), ('h', 61), ('i', 62), ('j', 63), ('k', 64), ('l', 65), ('m', 66), ('n', 67), ('o', 68), ('p', 69), ('q', 70), ('r', 71), ('s', 72), ('t', 73), ('u', 74), ('v', 75), ('w', 76), ('x', 77), ('y', 78), ('z', 79))\n"
     ]
    }
   ],
   "source": [
    "# Combine chars and token list into a zip object.\n",
    "map = zip(chars, tokens)\n",
    "\n",
    "# Visualize the zip object as a tuple.\n",
    "print(tuple(map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "317fd7ae-9457-4aa5-aafa-e5310128d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, '*': 8, ',': 9, '-': 10, '.': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'Z': 50, '[': 51, ']': 52, '_': 53, 'a': 54, 'b': 55, 'c': 56, 'd': 57, 'e': 58, 'f': 59, 'g': 60, 'h': 61, 'i': 62, 'j': 63, 'k': 64, 'l': 65, 'm': 66, 'n': 67, 'o': 68, 'p': 69, 'q': 70, 'r': 71, 's': 72, 't': 73, 'u': 74, 'v': 75, 'w': 76, 'x': 77, 'y': 78, 'z': 79}\n"
     ]
    }
   ],
   "source": [
    "# Convert the zip object into a dictionary.\n",
    "\n",
    "mapping = dict(zip(chars, tokens))\n",
    "\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f58746-f6e1-403f-b057-6f83a40e35c5",
   "metadata": {},
   "source": [
    "Then take user input. The input() function automatically converts input into string data type. For each character in the user input's string, map it to the integer token and return the results as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d960c153-4ec4-4fbb-9447-c0b71d52d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the phrase to convert?  TOKENS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your input is TOKENS, hence its token value according to mapping is:\n",
      "[79, 79, 79, 79, 79, 79]\n"
     ]
    }
   ],
   "source": [
    "text = input(\"What is the phrase to convert? \")\n",
    "tokenized = []\n",
    "for char in text:\n",
    "    tokenized.append(mapping[i])\n",
    "\n",
    "print(f\"Your input is {text}, hence its token value according to mapping is:\")\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e4533-ee87-4f7a-8a49-a7a0c9ac8fc6",
   "metadata": {},
   "source": [
    "## Code Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe11c84-bc5c-412c-89fd-df545844d55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "myllmproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
